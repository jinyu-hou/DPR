[2024-03-12 04:08:03,514][root][INFO] - CFG's local_rank=-1
[2024-03-12 04:08:03,514][root][INFO] - Env WORLD_SIZE=None
[2024-03-12 04:08:03,515][root][INFO] - Initialized host ip-172-31-67-199.ec2.internal as d.rank -1 on device=cuda, n_gpu=1, world size=1
[2024-03-12 04:08:03,515][root][INFO] - 16-bits training: False 
[2024-03-12 04:08:03,515][root][INFO] - CFG (after gpu  configuration):
[2024-03-12 04:08:03,521][root][INFO] - encoder:
  encoder_model_type: hf_bert
  pretrained_model_cfg: bert-base-uncased
  pretrained_file: null
  projection_dim: 0
  sequence_length: 256
  dropout: 0.1
  fix_ctx_encoder: false
  pretrained: true
train:
  batch_size: 16
  dev_batch_size: 16
  adam_eps: 1.0e-08
  adam_betas: (0.9, 0.999)
  max_grad_norm: 2.0
  log_batch_step: 1
  train_rolling_loss_step: 100
  weight_decay: 0.0
  learning_rate: 2.0e-05
  warmup_steps: 1237
  gradient_accumulation_steps: 1
  num_train_epochs: 40
  eval_per_epoch: 1
  hard_negatives: 1
  other_negatives: 0
  val_av_rank_hard_neg: 30
  val_av_rank_other_neg: 30
  val_av_rank_bsz: 128
  val_av_rank_max_qs: 10000
datasets:
  cmu_lti_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json
  cmu_lti_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_dev.json
  nq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-train
  nq_train_hn1:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-adv-hn-train
  nq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-dev
  trivia_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-train
  trivia_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-dev
  squad1_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-train
  squad1_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-dev
  webq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-train
  webq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-dev
  curatedtrec_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-train
  curatedtrec_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-dev
train_datasets:
- cmu_lti_train
dev_datasets:
- cmu_lti_dev
output_dir: /home/ec2-user/11711-a2/DPR/dpr/workdir
train_sampling_rates: null
loss_scale_factors: null
do_lower_case: true
val_av_rank_start_epoch: 30
seed: 12345
checkpoint_file_name: dpr_biencoder
model_file: /home/ec2-user/11711-a2/DPR/dpr/downloads/checkpoint/retriever/multiset/bert-base-encoder.cp
local_rank: -1
global_loss_buf_sz: 592000
device: cuda
distributed_world_size: 1
distributed_port: null
distributed_init_method: null
no_cuda: false
n_gpu: 1
fp16: false
fp16_opt_level: O1
special_tokens: null
ignore_checkpoint_offset: false
ignore_checkpoint_optimizer: false
ignore_checkpoint_lr: false
multi_q_encoder: false
local_shards_dataloader: false

[2024-03-12 04:08:03,522][root][INFO] - ***** Initializing components for training *****
[2024-03-12 04:08:03,522][root][INFO] - Reading saved model from /home/ec2-user/11711-a2/DPR/dpr/downloads/checkpoint/retriever/multiset/bert-base-encoder.cp
[2024-03-12 04:08:03,787][root][INFO] - model_state_dict keys odict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'offset', 'epoch', 'encoder_params'])
[2024-03-12 04:08:04,698][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2024-03-12 04:08:04,839][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2024-03-12 04:08:05,594][dpr.utils.conf_utils][INFO] - train_datasets: ['cmu_lti_train']
[2024-03-12 04:08:05,595][dpr.utils.conf_utils][INFO] - dev_datasets: ['cmu_lti_dev']
[2024-03-12 04:08:05,595][root][INFO] - Loading checkpoint @ batch=0 and epoch=1
[2024-03-12 04:08:05,595][root][INFO] - Loading saved model state ...
[2024-03-12 04:08:05,686][root][INFO] - Saved state loaded
[2024-03-12 04:08:05,709][root][INFO] - Initializing task/set data ['cmu_lti_train']
[2024-03-12 04:08:05,710][root][INFO] - Calculating shard positions
[2024-03-12 04:08:05,710][dpr.data.biencoder_data][INFO] - Loading all data
[2024-03-12 04:08:05,710][dpr.data.biencoder_data][INFO] - Data files: ['/home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json']
[2024-03-12 04:08:05,710][root][INFO] - Reading file /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json
[2024-03-12 04:08:08,420][root][INFO] - Aggregated data size: 15282
[2024-03-12 04:08:08,424][dpr.data.biencoder_data][INFO] - Total cleaned data size: 15282
[2024-03-12 04:08:08,424][root][INFO] - samples_per_shard=15282, shard_start_idx=0, shard_end_idx=15282, max_iterations=955
[2024-03-12 04:08:08,424][root][INFO] - Sharded dataset data 15282
[2024-03-12 04:08:08,424][root][INFO] - rank=-1; Multi set data sizes [15282]
[2024-03-12 04:08:08,424][root][INFO] - rank=-1; Multi set total data 15282
[2024-03-12 04:08:08,424][root][INFO] - rank=-1; Multi set sampling_rates None
[2024-03-12 04:08:08,424][root][INFO] - rank=-1; Multi set max_iterations per dataset [955]
[2024-03-12 04:08:08,424][root][INFO] - rank=-1; Multi set max_iterations 955
[2024-03-12 04:08:08,424][root][INFO] -   Total iterations per epoch=955
[2024-03-12 04:08:08,425][root][INFO] -  Total updates=38200
[2024-03-12 04:08:08,425][root][INFO] -   Eval step = 955
[2024-03-12 04:08:08,425][root][INFO] - ***** Training *****
[2024-03-12 04:08:08,425][root][INFO] - ***** Epoch 1 *****
[2024-03-12 04:08:08,426][root][INFO] - rank=-1; Iteration start
[2024-03-12 04:08:08,426][root][INFO] - rank=-1; Multi set iteration: iteration ptr per set: [0]
[2024-03-12 04:08:08,427][root][INFO] - rank=-1; Multi set iteration: source 0, batches to be taken: 955
[2024-03-12 04:08:08,427][root][INFO] - rank=-1; data_src_indices len=955
[2024-03-12 04:08:10,047][root][INFO] - Epoch: 1: Step: 1/955, loss=6.429261, lr=0.000000
[2024-03-12 04:08:10,715][root][INFO] - Epoch: 1: Step: 2/955, loss=4.944264, lr=0.000000
[2024-03-12 04:08:11,289][root][INFO] - Epoch: 1: Step: 3/955, loss=7.763630, lr=0.000000
[2024-03-12 04:08:11,864][root][INFO] - Epoch: 1: Step: 4/955, loss=5.415901, lr=0.000000
[2024-03-12 04:08:12,437][root][INFO] - Epoch: 1: Step: 5/955, loss=6.898104, lr=0.000000
[2024-03-12 04:08:13,012][root][INFO] - Epoch: 1: Step: 6/955, loss=6.694944, lr=0.000000
[2024-03-12 04:08:13,589][root][INFO] - Epoch: 1: Step: 7/955, loss=6.071314, lr=0.000000
[2024-03-12 04:08:14,164][root][INFO] - Epoch: 1: Step: 8/955, loss=7.270731, lr=0.000000
[2024-03-12 04:08:14,738][root][INFO] - Epoch: 1: Step: 9/955, loss=6.223462, lr=0.000000
[2024-03-12 04:08:15,313][root][INFO] - Epoch: 1: Step: 10/955, loss=5.360258, lr=0.000000
