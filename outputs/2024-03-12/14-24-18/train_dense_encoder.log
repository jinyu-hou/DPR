[2024-03-12 14:24:18,236][root][INFO] - CFG's local_rank=-1
[2024-03-12 14:24:18,236][root][INFO] - Env WORLD_SIZE=None
[2024-03-12 14:24:18,236][root][INFO] - Initialized host ip-172-31-67-199.ec2.internal as d.rank -1 on device=cuda, n_gpu=1, world size=1
[2024-03-12 14:24:18,236][root][INFO] - 16-bits training: False 
[2024-03-12 14:24:18,237][root][INFO] - CFG (after gpu  configuration):
[2024-03-12 14:24:18,243][root][INFO] - encoder:
  encoder_model_type: hf_bert
  pretrained_model_cfg: bert-base-uncased
  pretrained_file: null
  projection_dim: 0
  sequence_length: 256
  dropout: 0.1
  fix_ctx_encoder: false
  pretrained: true
train:
  batch_size: 24
  dev_batch_size: 24
  adam_eps: 1.0e-08
  adam_betas: (0.9, 0.999)
  max_grad_norm: 2.0
  log_batch_step: 1
  train_rolling_loss_step: 100
  weight_decay: 0.0
  learning_rate: 2.0e-05
  warmup_steps: 1237
  gradient_accumulation_steps: 1
  num_train_epochs: 3
  eval_per_epoch: 1
  hard_negatives: 1
  other_negatives: 0
  val_av_rank_hard_neg: 30
  val_av_rank_other_neg: 30
  val_av_rank_bsz: 128
  val_av_rank_max_qs: 10000
datasets:
  cmu_lti_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json
  cmu_lti_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_dev.json
  nq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-train
  nq_train_hn1:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-adv-hn-train
  nq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-dev
  trivia_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-train
  trivia_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-dev
  squad1_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-train
  squad1_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-dev
  webq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-train
  webq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-dev
  curatedtrec_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-train
  curatedtrec_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-dev
train_datasets:
- cmu_lti_train
dev_datasets:
- cmu_lti_dev
output_dir: /home/ec2-user/11711-a2/DPR/dpr/workdir
train_sampling_rates: null
loss_scale_factors: null
do_lower_case: true
val_av_rank_start_epoch: 30
seed: 12345
checkpoint_file_name: dpr_biencoder
model_file: /home/ec2-user/11711-a2/DPR/dpr/workdir/dpr_biencoder.29
local_rank: -1
global_loss_buf_sz: 592000
device: cuda
distributed_world_size: 1
distributed_port: null
distributed_init_method: null
no_cuda: false
n_gpu: 1
fp16: false
fp16_opt_level: O1
special_tokens: null
ignore_checkpoint_offset: false
ignore_checkpoint_optimizer: false
ignore_checkpoint_lr: false
multi_q_encoder: false
local_shards_dataloader: false

[2024-03-12 14:24:18,243][root][INFO] - ***** Initializing components for training *****
[2024-03-12 14:24:18,244][root][INFO] - Reading saved model from /home/ec2-user/11711-a2/DPR/dpr/workdir/dpr_biencoder.29
[2024-03-12 14:24:19,037][root][INFO] - model_state_dict keys dict_keys(['model_dict', 'optimizer_dict', 'scheduler_dict', 'offset', 'epoch', 'encoder_params'])
[2024-03-12 14:24:19,939][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2024-03-12 14:24:20,184][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2024-03-12 14:24:20,794][dpr.utils.conf_utils][INFO] - train_datasets: ['cmu_lti_train']
[2024-03-12 14:24:20,795][dpr.utils.conf_utils][INFO] - dev_datasets: ['cmu_lti_dev']
[2024-03-12 14:24:20,795][root][INFO] - Loading checkpoint @ batch=636 and epoch=29
[2024-03-12 14:24:20,795][root][INFO] - Loading saved model state ...
[2024-03-12 14:24:20,885][root][INFO] - Saved state loaded
[2024-03-12 14:24:20,885][root][INFO] - Using saved optimizer state
[2024-03-12 14:24:21,068][root][INFO] - Using saved scheduler_state
[2024-03-12 14:24:21,137][root][INFO] - Initializing task/set data ['cmu_lti_train']
[2024-03-12 14:24:21,137][root][INFO] - Calculating shard positions
[2024-03-12 14:24:21,137][dpr.data.biencoder_data][INFO] - Loading all data
[2024-03-12 14:24:21,137][dpr.data.biencoder_data][INFO] - Data files: ['/home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json']
[2024-03-12 14:24:21,137][root][INFO] - Reading file /home/ec2-user/11711-a2/11711-End-to-end-NLP-System-Building/70B_retriever_train.json
[2024-03-12 14:24:23,779][root][INFO] - Aggregated data size: 15282
[2024-03-12 14:24:23,783][dpr.data.biencoder_data][INFO] - Total cleaned data size: 15282
[2024-03-12 14:24:23,784][root][INFO] - samples_per_shard=15282, shard_start_idx=0, shard_end_idx=15282, max_iterations=636
[2024-03-12 14:24:23,784][root][INFO] - Sharded dataset data 15282
[2024-03-12 14:24:23,784][root][INFO] - rank=-1; Multi set data sizes [15282]
[2024-03-12 14:24:23,784][root][INFO] - rank=-1; Multi set total data 15282
[2024-03-12 14:24:23,784][root][INFO] - rank=-1; Multi set sampling_rates None
[2024-03-12 14:24:23,784][root][INFO] - rank=-1; Multi set max_iterations per dataset [636]
[2024-03-12 14:24:23,784][root][INFO] - rank=-1; Multi set max_iterations 636
[2024-03-12 14:24:23,784][root][INFO] -   Total iterations per epoch=636
[2024-03-12 14:24:23,784][root][INFO] -  Total updates=1908
[2024-03-12 14:24:23,784][root][INFO] - Loading scheduler state {'base_lrs': [2e-05, 2e-05], 'last_epoch': 18444, 'verbose': False, '_step_count': 18445, '_get_lr_called_within_step': False, '_last_lr': [5.78110151634095e-06, 5.78110151634095e-06], 'lr_lambdas': [None, None]}
[2024-03-12 14:24:23,784][root][INFO] - Steps shift 18444
[2024-03-12 14:24:23,784][root][INFO] -   Eval step = 636
[2024-03-12 14:24:23,784][root][INFO] - ***** Training *****
[2024-03-12 14:24:23,785][root][INFO] - Training finished. Best validation checkpoint None
